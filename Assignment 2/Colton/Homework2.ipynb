{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words('english'))\n",
    "austen = nltk.corpus.gutenberg.words('austen-sense.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Jane Austen's **Sense**\n",
    "## [1] Preprocessing\n",
    "* Remove all non-words\n",
    "* ~~Remove all stop words~~\n",
    "* Lowercase\n",
    "\n",
    "I looked into removing stop words, but using NLTK.corpus.stopwords reduced the total number of tokens to ~58k, too low per the instructions. Stemming and lemmatizing would further reduce this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "austen = ' '.join(austen)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "austen = tokenizer.tokenize(austen) # remove nonwords\n",
    "# austen = [word for word in austen if not word in stop_words] # remove stop words\n",
    "austen_list = [word.lower() for word in austen] # lowercase\n",
    "austen_str = ' '.join(austen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.1] Word-to-Int mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = Counter()\n",
    "tokens = austen_str.lower().split()\n",
    "for token in tokens:\n",
    "    freqs[token] += 1                                 # freqs is dict(), i.e. freqs[word] = count\n",
    "freqs = freqs.most_common()                   # now freqs is tuple of (word, count)\n",
    "mapping = {freqs[i][0]:i+1 for i in range(len(freqs))}  # mapping is dict of freqs[word]=r where r=rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2] Split the corpus into documents on the word \"chapter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 118236\n",
      "Number of unique tokens: 6336\n",
      "Number of documents: 49\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "start = 0\n",
    "i = 0\n",
    "while i < len(austen_list):\n",
    "    if austen_list[i] == 'chapter':\n",
    "        docs.append(austen_list[start:i-1])\n",
    "        start = i\n",
    "    i += 1\n",
    "    \n",
    "docs = docs[1:]\n",
    "N_W = sum(len(doc) for doc in docs)\n",
    "N_W_unique = len(set(austen_list))\n",
    "N_D = len(docs)\n",
    "print('Total number of tokens: ' + str(N_W))\n",
    "print('Number of unique tokens: ' + str(N_W_unique))\n",
    "print('Number of documents: ' + str(N_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3] Create word-to-int mapped matrix\n",
    "The rows of the matrix will be documents and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapsed Gibbs Sampling\n",
    "$\\alpha$ = $\\beta$ = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_K = 10\n",
    "T = 10\n",
    "alpha = 0.01\n",
    "beta = alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndw = np.random.randint(low=0, high=N_K, size=(N_D, N_W)) # Z\n",
    "ndk = np.zeros((N_D, N_K)) # Pi\n",
    "nkw = np.zeros((N_K, N_W)) # B\n",
    "for i in range(N_D):\n",
    "    ndk[i] = np.random.dirichlet(alpha * np.ones(N_K))\n",
    "for i in range(N_K):\n",
    "    nkw[i] = np.random.dirichlet(beta * np.ones(N_W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.31122896e-031, 1.15679443e-007, 1.59470696e-010, 1.20598730e-102,\n",
       "       2.87670449e-044, 3.99890367e-009, 2.21264749e-061, 1.65514186e-069,\n",
       "       9.99996581e-001, 3.29923486e-006])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in range(T):\n",
    "    for i in range(N_D):\n",
    "        for j in range(N_W):\n",
    "            p_ij = np.exp(np.log(ndk[i]) + np.log(nkw[:, ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nkw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d1970a8f3a2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnkw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nkw' is not defined"
     ]
    }
   ],
   "source": [
    "nkw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-f6e7c0610b57>:1: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
